{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95d7b06",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-19T21:20:36.598969Z",
     "iopub.status.busy": "2024-10-19T21:20:36.598133Z",
     "iopub.status.idle": "2024-10-19T21:23:54.625730Z",
     "shell.execute_reply": "2024-10-19T21:23:54.624605Z"
    },
    "papermill": {
     "duration": 198.034965,
     "end_time": "2024-10-19T21:23:54.628030",
     "exception": false,
     "start_time": "2024-10-19T21:20:36.593065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git\r\n",
      "  Cloning https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git to /tmp/pip-req-build-473n86ym\r\n",
      "  Running command git clone --filter=blob:none --quiet 'https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git' /tmp/pip-req-build-473n86ym\r\n",
      "  Resolved https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git to commit 63482c4c83a3a4ea3b38db074ceba04486fc05e7\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (8.1.1)\r\n",
      "Collecting torch==2.3.0 (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "Collecting torchvision==0.18.0 (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\r\n",
      "Collecting torchaudio==2.3.0 (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.66.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.7.5)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.2.2)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.22.0)\r\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.12.2)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (6.0.1)\r\n",
      "Collecting yacs (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\r\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.26.4)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.9.0.80)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2024.2.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.3.0 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.18.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (9.5.0)\r\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.9.0.post0)\r\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.0.0)\r\n",
      "Requirement already satisfied: pluggy<2.0,>=1.4 in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.4.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.2.0)\r\n",
      "Requirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.0.1)\r\n",
      "Requirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.11.4)\r\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.33.1)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2023.12.9)\r\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.4.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.2.0)\r\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.10/site-packages (from seaborn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.1.4)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2023.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.3.0)\r\n",
      "Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m970.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m898.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\r\n",
      "Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: HTCV_DeeplabV3Plus_MaterialSegmentation\r\n",
      "  Building wheel for HTCV_DeeplabV3Plus_MaterialSegmentation (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for HTCV_DeeplabV3Plus_MaterialSegmentation: filename=HTCV_DeeplabV3Plus_MaterialSegmentation-0.0.1-py3-none-any.whl size=5844587 sha256=d8f57078bee20564c3d88608f4eb4caca55c4d1a72251d1e9196eda616289f27\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sct7sn0s/wheels/3a/dd/47/f7229c606648c55ebb6dd9026436f12245ae6107f066c04dc8\r\n",
      "Successfully built HTCV_DeeplabV3Plus_MaterialSegmentation\r\n",
      "Installing collected packages: yacs, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio, HTCV_DeeplabV3Plus_MaterialSegmentation\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.1.2\r\n",
      "    Uninstalling torch-2.1.2:\r\n",
      "      Successfully uninstalled torch-2.1.2\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.16.2\r\n",
      "    Uninstalling torchvision-0.16.2:\r\n",
      "      Successfully uninstalled torchvision-0.16.2\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 2.1.2\r\n",
      "    Uninstalling torchaudio-2.1.2:\r\n",
      "      Successfully uninstalled torchaudio-2.1.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.7.14 requires torch<2.3,>=1.10, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed HTCV_DeeplabV3Plus_MaterialSegmentation-0.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 torchaudio-2.3.0 torchvision-0.18.0 triton-2.3.0 yacs-0.1.8\r\n"
     ]
    }
   ],
   "source": [
    "token = \"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\"#token here\n",
    "user = \"haaroonafroz\" #username here\n",
    "repo_name = \"DeeplabV3Plus_MaterialSegmentation\" #repository name here\n",
    "url = f\"https://{user}:{token}@github.com/{user}/{repo_name}.git\"\n",
    "\n",
    "!pip install git+{url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9547e4ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T21:23:54.905871Z",
     "iopub.status.busy": "2024-10-19T21:23:54.905388Z",
     "iopub.status.idle": "2024-10-19T21:23:54.931956Z",
     "shell.execute_reply": "2024-10-19T21:23:54.930706Z"
    },
    "papermill": {
     "duration": 0.166443,
     "end_time": "2024-10-19T21:23:54.934161",
     "exception": false,
     "start_time": "2024-10-19T21:23:54.767718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repository_content/\n",
      "    visualize.py\n",
      "    config.py\n",
      "    __init__.py\n",
      "    model.py\n",
      "    utils.py\n",
      "    train.py\n",
      "    plot.py\n",
      "    dataset.py\n",
      "    training.py\n",
      "    __pycache__/\n",
      "        plot.cpython-310.pyc\n",
      "        dataset.cpython-310.pyc\n",
      "        train.cpython-310.pyc\n",
      "        utils.cpython-310.pyc\n",
      "        config.cpython-310.pyc\n",
      "        model.cpython-310.pyc\n",
      "        training.cpython-310.pyc\n",
      "        visualize.cpython-310.pyc\n",
      "        __init__.cpython-310.pyc\n",
      "    predictions/\n",
      "        airplane_prediction.png\n",
      "        Bunny_scene_confidence_maps.png\n",
      "        airplane_segmentation_with_boundaries.png\n",
      "        bicycle_prediction.png\n",
      "        boat_prediction.png\n",
      "        boat_confidence_maps_boat_kaggle.png\n",
      "        image_0036_m_prediction.png\n",
      "        bicycle_confidence_maps_Kaggle.png\n",
      "        Confidence_heatmap_airplane.png\n",
      "        boat_confidence_maps.png\n",
      "        boat_segmentation_with_boundaries.png\n",
      "        airplane_confidence_maps_Kaggle.png\n",
      "        airplane_confidence_maps.png\n",
      "    results/\n",
      "        .gitkeep\n",
      "    images/\n",
      "        bottle_glass_blackbg.jpg\n",
      "        chair_wood_blackbg.jpg\n",
      "        bicycle.jpg\n",
      "        boat.jpg\n",
      "        chair_wood.jpg\n",
      "        person_dog.jpg\n",
      "        chair_wood_blackbg1.jpg\n",
      "        .gitkeep\n",
      "        airplane.jpg\n",
      "        Bunny_scene.jpg\n",
      "    config/\n",
      "        config1.yaml\n",
      "        config_kaggle.yaml\n",
      "        config2.yaml\n",
      "        config3.yaml\n",
      "    saved_models/\n",
      "        underfitting_run.pth\n",
      "        fixture_weights_dont_delete_this.pth\n",
      "        test_model.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import dlcv  # Assuming the repository is installed and accessible as a Python package\n",
    "\n",
    "# Determine the source directory from the installed package location\n",
    "source_dir = os.path.dirname(dlcv.__file__)\n",
    "destination_dir = os.path.join(os.getcwd(), 'repository_content')\n",
    "\n",
    "# Create the destination directory\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Copy contents from the source directory to the destination directory\n",
    "for item in os.listdir(source_dir):\n",
    "    source_item = os.path.join(source_dir, item)\n",
    "    destination_item = os.path.join(destination_dir, item)\n",
    "    if os.path.isdir(source_item):\n",
    "        shutil.copytree(source_item, destination_item, dirs_exist_ok=True)\n",
    "    else:\n",
    "        shutil.copy2(source_item, destination_item)\n",
    "\n",
    "# List the contents of the destination directory\n",
    "for root, dirs, files in os.walk(destination_dir):\n",
    "    level = root.replace(destination_dir, '').count(os.sep)\n",
    "    indent = ' ' * 4 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 4 * (level + 1)\n",
    "    for f in files:\n",
    "        print(f\"{subindent}{f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c81fe9",
   "metadata": {
    "papermill": {
     "duration": 0.137317,
     "end_time": "2024-10-19T21:23:55.209529",
     "exception": false,
     "start_time": "2024-10-19T21:23:55.072212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration for 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22334d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T21:23:55.483941Z",
     "iopub.status.busy": "2024-10-19T21:23:55.483611Z",
     "iopub.status.idle": "2024-10-19T21:24:02.991486Z",
     "shell.execute_reply": "2024-10-19T21:24:02.990530Z"
    },
    "papermill": {
     "duration": 7.648163,
     "end_time": "2024-10-19T21:24:02.993996",
     "exception": false,
     "start_time": "2024-10-19T21:23:55.345833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file saved at: /kaggle/working/create_config/Semantic_Segmentation_50Epochs_NewDataset.yaml\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 10\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-new/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: ''\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Semantic_Segmentation_50Epochs_NewDataset\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_models\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 5\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0002\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dlcv.utils import create_config\n",
    "#this function from utils.py takes the following arguments\n",
    "run_name = 'Semantic_Segmentation_50Epochs_NewDataset'\n",
    "root = '/kaggle/input/material-dataset-new/Material_dataset'\n",
    "\n",
    "# Choose a Backbone for the FasterRCNN Model\n",
    "backbone = 'mobilenet'   # (Options- 'resnet50', 'resnet101', 'mobilenet')\n",
    "\n",
    "# Scheduler and Optimizer Hyper-Parameters.\n",
    "base_lr = 0.0002  # Learning Rate\n",
    "milestones = [10, 20]\n",
    "gamma = 0.1\n",
    "\n",
    "# Training Hyper-Parameters\n",
    "batch_size = 8          #(Resnet50: 4, Resnet101: 2, MobileNet: 8)\n",
    "num_epochs = 50         #(Avg. Time per Epoch: Resnet50- 4:20, Resnet101- 5:45, Mobilenet: 3:43 )\n",
    "early_stopping = False\n",
    "\n",
    "# Augmentation Parameters\n",
    "horizontal_flip_prob = 0.5\n",
    "rotation_degrees = 10\n",
    "crop_size = [256,256]\n",
    "pretrained_weights= ''#'/kaggle/input/deeplabv3plus_newmodel/pytorch/default/1/Semantic_Segmentation_50Epochs_NewModel.pth'\n",
    "save_path = '/kaggle/working/saved_models'\n",
    "\n",
    "config_file_path = create_config(run_name, backbone, base_lr,\n",
    "                                 batch_size, num_epochs, horizontal_flip_prob,\n",
    "                                rotation_degrees, crop_size, milestones, gamma, \n",
    "                                early_stopping, pretrained_weights, save_path, root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21e14b69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T21:24:03.275291Z",
     "iopub.status.busy": "2024-10-19T21:24:03.274066Z",
     "iopub.status.idle": "2024-10-19T21:24:03.279485Z",
     "shell.execute_reply": "2024-10-19T21:24:03.278632Z"
    },
    "papermill": {
     "duration": 0.147458,
     "end_time": "2024-10-19T21:24:03.281380",
     "exception": false,
     "start_time": "2024-10-19T21:24:03.133922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Path to the config file you want to use\n",
    "#config_file = 'config_kaggle.yaml'#yaml file name here\n",
    "#config_file_path = '/kaggle/working/repository_content/config/' + config_file\n",
    "os.environ['CONFIG_FILE'] = config_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb73a9df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T21:24:03.561969Z",
     "iopub.status.busy": "2024-10-19T21:24:03.561519Z",
     "iopub.status.idle": "2024-10-20T05:34:02.001976Z",
     "shell.execute_reply": "2024-10-20T05:34:02.000911Z"
    },
    "papermill": {
     "duration": 29400.996994,
     "end_time": "2024-10-20T05:34:04.417434",
     "exception": false,
     "start_time": "2024-10-19T21:24:03.420440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/material_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
      "  0%|          | 0.00/13.6M [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using configuration file: /kaggle/working/create_config/Semantic_Segmentation_50Epochs_NewDataset.yaml\n",
      "Configuration for this run:\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 10\n",
      "CONFIG_FILE_PATH: /kaggle/working/create_config/Semantic_Segmentation_50Epochs_NewDataset.yaml\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-new/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: ''\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Semantic_Segmentation_50Epochs_NewDataset\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_models\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 5\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0002\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 50\n",
      "\n",
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 129MB/s]\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Training: 100%|██████████| 2000/2000 [09:07<00:00,  3.65it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.7158, Test Loss: 0.2683, Test IoU (Material): 0.3413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:06<00:00,  3.66it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Train Loss: 0.4884, Test Loss: 0.5923, Test IoU (Material): 0.1762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:43<00:00,  3.82it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Train Loss: 0.5061, Test Loss: 0.5922, Test IoU (Material): 0.1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:43<00:00,  3.82it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Train Loss: 0.4512, Test Loss: 0.2012, Test IoU (Material): 0.2673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:47<00:00,  3.79it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Train Loss: 0.4662, Test Loss: 0.5386, Test IoU (Material): 0.1848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:03<00:00,  3.68it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Train Loss: 0.4418, Test Loss: 0.7520, Test IoU (Material): 0.0945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:59<00:00,  3.71it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Train Loss: 0.5181, Test Loss: 0.4466, Test IoU (Material): 0.2149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:50<00:00,  3.77it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Train Loss: 0.3958, Test Loss: 0.8593, Test IoU (Material): 0.0822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:55<00:00,  3.74it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Train Loss: 0.4802, Test Loss: 0.0472, Test IoU (Material): 0.3800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:28<00:00,  3.94it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:27<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Train Loss: 0.5197, Test Loss: 0.5239, Test IoU (Material): 0.3257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:49<00:00,  3.78it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Train Loss: 0.4251, Test Loss: -0.0637, Test IoU (Material): 0.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:00<00:00,  3.70it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Train Loss: 0.7238, Test Loss: 0.8019, Test IoU (Material): 0.1810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:02<00:00,  3.69it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Train Loss: 0.5450, Test Loss: 0.2383, Test IoU (Material): 0.2160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:56<00:00,  3.72it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Train Loss: 0.5764, Test Loss: 0.8323, Test IoU (Material): 0.2171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:55<00:00,  3.73it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Train Loss: 0.6620, Test Loss: 0.5351, Test IoU (Material): 0.2324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:59<00:00,  3.71it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:27<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Train Loss: 0.4833, Test Loss: -0.4180, Test IoU (Material): 0.3143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:52<00:00,  3.76it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Train Loss: 0.5463, Test Loss: 0.4045, Test IoU (Material): 0.1983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:45<00:00,  3.81it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Train Loss: 0.5486, Test Loss: 0.9269, Test IoU (Material): 0.2794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:12<00:00,  4.06it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Train Loss: 0.5093, Test Loss: 0.4794, Test IoU (Material): 0.2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:15<00:00,  4.04it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Train Loss: 0.4495, Test Loss: 1.4562, Test IoU (Material): 0.1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [07:59<00:00,  4.17it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Train Loss: 0.7372, Test Loss: 0.5059, Test IoU (Material): 0.1924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [05:09<00:00,  6.46it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Train Loss: 6.0714, Test Loss: 4.2708, Test IoU (Material): 0.1947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:08<00:00,  8.06it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Train Loss: -3.6942, Test Loss: -0.1660, Test IoU (Material): 0.1971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:01<00:00,  8.28it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Train Loss: 0.7426, Test Loss: 0.9729, Test IoU (Material): 0.1908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [03:53<00:00,  8.55it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Train Loss: 0.7557, Test Loss: 0.4407, Test IoU (Material): 0.1978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [05:18<00:00,  6.28it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:27<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Train Loss: 0.9912, Test Loss: 0.4070, Test IoU (Material): 0.1866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [05:52<00:00,  5.67it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Train Loss: 0.5516, Test Loss: 0.2360, Test IoU (Material): 0.1788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:07<00:00,  8.07it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Train Loss: -4.7079, Test Loss: 0.4534, Test IoU (Material): 0.1769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [03:48<00:00,  8.74it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Train Loss: 0.9675, Test Loss: 5.1654, Test IoU (Material): 0.1853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:03<00:00,  8.23it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Train Loss: 0.7713, Test Loss: -3.0410, Test IoU (Material): 0.1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:14<00:00,  7.85it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Train Loss: 0.8556, Test Loss: 0.9054, Test IoU (Material): 0.1813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:22<00:00,  7.62it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Train Loss: 0.9012, Test Loss: 1.6901, Test IoU (Material): 0.1783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:53<00:00,  6.81it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Train Loss: 1.2675, Test Loss: 0.4932, Test IoU (Material): 0.1763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:19<00:00,  7.72it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Train Loss: 1.4531, Test Loss: 0.4751, Test IoU (Material): 0.1808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:02<00:00,  8.23it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Train Loss: 0.7410, Test Loss: -0.9315, Test IoU (Material): 0.1801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:29<00:00,  7.41it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Train Loss: 1.2341, Test Loss: 0.3243, Test IoU (Material): 0.1774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:16<00:00,  7.80it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Train Loss: 0.7613, Test Loss: -0.0582, Test IoU (Material): 0.1765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:17<00:00,  7.75it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Train Loss: 0.7146, Test Loss: 0.8785, Test IoU (Material): 0.1723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:20<00:00,  7.67it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Train Loss: 1.0714, Test Loss: 1.0929, Test IoU (Material): 0.1693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:11<00:00,  7.97it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Train Loss: 0.8918, Test Loss: 0.4991, Test IoU (Material): 0.1809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:14<00:00,  7.87it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Train Loss: 0.9200, Test Loss: 0.4683, Test IoU (Material): 0.1749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:15<00:00,  7.82it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Train Loss: 0.8938, Test Loss: 0.3465, Test IoU (Material): 0.1763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:28<00:00,  7.46it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Train Loss: 0.6704, Test Loss: 0.7810, Test IoU (Material): 0.1729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [05:25<00:00,  6.15it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Train Loss: 0.8315, Test Loss: 0.4623, Test IoU (Material): 0.1783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:41<00:00,  7.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Train Loss: 0.6437, Test Loss: 0.3977, Test IoU (Material): 0.1786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:19<00:00,  7.71it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Train Loss: 0.7408, Test Loss: 0.5768, Test IoU (Material): 0.1791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:47<00:00,  6.95it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Train Loss: 1.7327, Test Loss: 0.7638, Test IoU (Material): 0.1767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:18<00:00,  7.73it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Train Loss: 1.0697, Test Loss: 0.5613, Test IoU (Material): 0.1755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:25<00:00,  7.53it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Train Loss: -0.5811, Test Loss: 0.8633, Test IoU (Material): 0.1769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:08<00:00,  8.06it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Train Loss: 0.6184, Test Loss: 0.3439, Test IoU (Material): 0.1799\n",
      "Train Loss: 0.6184, Test Loss: 0.3439, Test IoU (Material): 0.1799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'repository_content/train.py', '--config', '/kaggle/working/create_config/Semantic_Segmentation_50Epochs_NewDataset.yaml', '--mode', 'train'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from dlcv.train import main as train_main\n",
    "from dlcv.config import get_cfg_defaults\n",
    "cfg = get_cfg_defaults()\n",
    "print(cfg.DATA.MATERIAL_ROOT)\n",
    "subprocess.run(['python', 'repository_content/train.py', '--config', config_file_path, '--mode', 'train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0da8655c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T05:34:17.984111Z",
     "iopub.status.busy": "2024-10-20T05:34:17.983344Z",
     "iopub.status.idle": "2024-10-20T05:34:17.995768Z",
     "shell.execute_reply": "2024-10-20T05:34:17.994711Z"
    },
    "papermill": {
     "duration": 6.793606,
     "end_time": "2024-10-20T05:34:17.997683",
     "exception": false,
     "start_time": "2024-10-20T05:34:11.204077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file saved at: /kaggle/working/create_config/Visualization_100Epochs.yaml\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 11\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-new/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: /kaggle/input/deeplabv3plus_newmodel/pytorch/newmodel_100epochs/1/Semantic_Segmentation_100Epochs_NewModel.pth\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Visualization_100Epochs\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_prediction\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 5\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0005\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#this function from utils.py takes the following arguments\n",
    "from dlcv.utils import create_config\n",
    "run_name = 'Visualization_100Epochs'\n",
    "\n",
    "# Choose a Backbone for the FasterRCNN Model\n",
    "backbone = 'mobilenet'   # (Options- 'resnet50', 'resnet101', 'mobilenet')\n",
    "\n",
    "# Scheduler and Optimizer Hyper-Parameters.\n",
    "base_lr = 0.0005  # Learning Rate\n",
    "milestones = [10, 20]\n",
    "gamma = 0.1\n",
    "\n",
    "# Training Hyper-Parameters\n",
    "batch_size = 8          #(Resnet50: 4, Resnet101: 2, MobileNet: 8)\n",
    "num_epochs = 1         #(Avg. Time per Epoch: Resnet50- 4:20, Resnet101- 5:45, Mobilenet: 3:43 )\n",
    "early_stopping = False\n",
    "\n",
    "# Augmentation Parameters\n",
    "horizontal_flip_prob = 0.5\n",
    "rotation_degrees = 11\n",
    "crop_size = [256,256]\n",
    "\n",
    "pretrained_weights= '/kaggle/input/deeplabv3plus_newmodel/pytorch/newmodel_100epochs/1/Semantic_Segmentation_100Epochs_NewModel.pth'\n",
    "save_path = '/kaggle/working/saved_prediction'\n",
    "config_file_path = create_config(run_name, backbone, base_lr,\n",
    "                                 batch_size, num_epochs, horizontal_flip_prob,\n",
    "                                rotation_degrees, crop_size, milestones, gamma,\n",
    "                                early_stopping, pretrained_weights, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3808f8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T05:34:31.735524Z",
     "iopub.status.busy": "2024-10-20T05:34:31.734816Z",
     "iopub.status.idle": "2024-10-20T05:34:46.658561Z",
     "shell.execute_reply": "2024-10-20T05:34:46.657523Z"
    },
    "papermill": {
     "duration": 21.92431,
     "end_time": "2024-10-20T05:34:46.660717",
     "exception": false,
     "start_time": "2024-10-20T05:34:24.736407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using configuration file: /kaggle/working/create_config/Visualization_100Epochs.yaml\n",
      "Configuration for this run:\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 11\n",
      "CONFIG_FILE_PATH: /kaggle/working/create_config/Visualization_100Epochs.yaml\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-new/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: /kaggle/input/deeplabv3plus_newmodel/pytorch/newmodel_100epochs/1/Semantic_Segmentation_100Epochs_NewModel.pth\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Visualization_100Epochs\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_prediction\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 5\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0005\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 1\n",
      "\n",
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'repository_content/train.py', '--config', '/kaggle/working/create_config/Visualization_100Epochs.yaml', '--mode', 'single_image', '--image_path', '/kaggle/working/repository_content/images/airplane.jpg'], returncode=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run(['python', 'repository_content/train.py', '--config', config_file_path, '--mode', 'single_image', '--image_path', '/kaggle/working/repository_content/images/airplane.jpg'])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5908856,
     "sourceId": 9669620,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 139721,
     "modelInstanceId": 116497,
     "sourceId": 137609,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 139721,
     "modelInstanceId": 117686,
     "sourceId": 138965,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29661.133673,
   "end_time": "2024-10-20T05:34:54.874569",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-19T21:20:33.740896",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
