{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee4dec41",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-21T19:07:51.643805Z",
     "iopub.status.busy": "2024-10-21T19:07:51.643195Z",
     "iopub.status.idle": "2024-10-21T19:10:31.152323Z",
     "shell.execute_reply": "2024-10-21T19:10:31.151251Z"
    },
    "papermill": {
     "duration": 159.516003,
     "end_time": "2024-10-21T19:10:31.154537",
     "exception": false,
     "start_time": "2024-10-21T19:07:51.638534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git\r\n",
      "  Cloning https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git to /tmp/pip-req-build-1cyqkb7h\r\n",
      "  Running command git clone --filter=blob:none --quiet 'https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git' /tmp/pip-req-build-1cyqkb7h\r\n",
      "  Resolved https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git to commit eda2fa09c8e37e41e3de3918a200db0482fe528c\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (8.1.1)\r\n",
      "Collecting torch==2.3.0 (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "Collecting torchvision==0.18.0 (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\r\n",
      "Collecting torchaudio==2.3.0 (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.66.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.7.5)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.2.2)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.22.0)\r\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.12.2)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (6.0.1)\r\n",
      "Collecting yacs (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\r\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.26.4)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.9.0.80)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2024.2.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.3.0 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.18.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (9.5.0)\r\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.9.0.post0)\r\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.0.0)\r\n",
      "Requirement already satisfied: pluggy<2.0,>=1.4 in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.4.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.2.0)\r\n",
      "Requirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.0.1)\r\n",
      "Requirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.11.4)\r\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.33.1)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2023.12.9)\r\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.4.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.2.0)\r\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.10/site-packages (from seaborn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.1.4)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2023.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.3.0)\r\n",
      "Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\r\n",
      "Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: HTCV_DeeplabV3Plus_MaterialSegmentation\r\n",
      "  Building wheel for HTCV_DeeplabV3Plus_MaterialSegmentation (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for HTCV_DeeplabV3Plus_MaterialSegmentation: filename=HTCV_DeeplabV3Plus_MaterialSegmentation-0.0.1-py3-none-any.whl size=5793731 sha256=a3a8abce89cb6c4cd3efd11b3e3c5ce45d574b9e0fbcf597bf3999e785f3b3c3\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vkol5hu5/wheels/3a/dd/47/f7229c606648c55ebb6dd9026436f12245ae6107f066c04dc8\r\n",
      "Successfully built HTCV_DeeplabV3Plus_MaterialSegmentation\r\n",
      "Installing collected packages: yacs, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio, HTCV_DeeplabV3Plus_MaterialSegmentation\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.1.2\r\n",
      "    Uninstalling torch-2.1.2:\r\n",
      "      Successfully uninstalled torch-2.1.2\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.16.2\r\n",
      "    Uninstalling torchvision-0.16.2:\r\n",
      "      Successfully uninstalled torchvision-0.16.2\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 2.1.2\r\n",
      "    Uninstalling torchaudio-2.1.2:\r\n",
      "      Successfully uninstalled torchaudio-2.1.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.7.14 requires torch<2.3,>=1.10, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed HTCV_DeeplabV3Plus_MaterialSegmentation-0.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 torchaudio-2.3.0 torchvision-0.18.0 triton-2.3.0 yacs-0.1.8\r\n"
     ]
    }
   ],
   "source": [
    "token = \"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\"#token here\n",
    "user = \"haaroonafroz\" #username here\n",
    "repo_name = \"DeeplabV3Plus_MaterialSegmentation\" #repository name here\n",
    "url = f\"https://{user}:{token}@github.com/{user}/{repo_name}.git\"\n",
    "\n",
    "!pip install git+{url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aec4847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T19:10:31.308072Z",
     "iopub.status.busy": "2024-10-21T19:10:31.307734Z",
     "iopub.status.idle": "2024-10-21T19:10:31.332985Z",
     "shell.execute_reply": "2024-10-21T19:10:31.331702Z"
    },
    "papermill": {
     "duration": 0.103965,
     "end_time": "2024-10-21T19:10:31.334915",
     "exception": false,
     "start_time": "2024-10-21T19:10:31.230950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repository_content/\n",
      "    config.py\n",
      "    utils.py\n",
      "    train.py\n",
      "    training_unet.py\n",
      "    training.py\n",
      "    __init__.py\n",
      "    visualize.py\n",
      "    plot.py\n",
      "    model.py\n",
      "    dataset.py\n",
      "    saved_models/\n",
      "        fixture_weights_dont_delete_this.pth\n",
      "        underfitting_run.pth\n",
      "        test_model.pth\n",
      "    images/\n",
      "        bicycle.jpg\n",
      "        Bunny_scene.jpg\n",
      "        .gitkeep\n",
      "        boat.jpg\n",
      "        chair_wood_blackbg.jpg\n",
      "        bottle_glass_blackbg.jpg\n",
      "        chair_wood_blackbg1.jpg\n",
      "        person_dog.jpg\n",
      "        chair_wood.jpg\n",
      "        airplane.jpg\n",
      "    results/\n",
      "        .gitkeep\n",
      "    __pycache__/\n",
      "        utils.cpython-310.pyc\n",
      "        dataset.cpython-310.pyc\n",
      "        config.cpython-310.pyc\n",
      "        training.cpython-310.pyc\n",
      "        visualize.cpython-310.pyc\n",
      "        training_unet.cpython-310.pyc\n",
      "        __init__.cpython-310.pyc\n",
      "        model.cpython-310.pyc\n",
      "        train.cpython-310.pyc\n",
      "        plot.cpython-310.pyc\n",
      "    predictions/\n",
      "        boat_confidence_maps.png\n",
      "        bicycle_confidence_maps_Kaggle.png\n",
      "        boat_prediction.png\n",
      "        airplane_prediction.png\n",
      "        bicycle_prediction.png\n",
      "        boat_confidence_maps_boat_kaggle.png\n",
      "        Bunny_scene_confidence_maps.png\n",
      "        boat_segmentation_with_boundaries.png\n",
      "        airplane_confidence_maps_Kaggle.png\n",
      "        airplane_segmentation_with_boundaries.png\n",
      "        Confidence_heatmap_airplane.png\n",
      "        image_0036_m_prediction.png\n",
      "        airplane_confidence_maps.png\n",
      "    config/\n",
      "        config2.yaml\n",
      "        config_kaggle.yaml\n",
      "        config1.yaml\n",
      "        config3.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import dlcv  # Assuming the repository is installed and accessible as a Python package\n",
    "\n",
    "# Determine the source directory from the installed package location\n",
    "source_dir = os.path.dirname(dlcv.__file__)\n",
    "destination_dir = os.path.join(os.getcwd(), 'repository_content')\n",
    "\n",
    "# Create the destination directory\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Copy contents from the source directory to the destination directory\n",
    "for item in os.listdir(source_dir):\n",
    "    source_item = os.path.join(source_dir, item)\n",
    "    destination_item = os.path.join(destination_dir, item)\n",
    "    if os.path.isdir(source_item):\n",
    "        shutil.copytree(source_item, destination_item, dirs_exist_ok=True)\n",
    "    else:\n",
    "        shutil.copy2(source_item, destination_item)\n",
    "\n",
    "# List the contents of the destination directory\n",
    "for root, dirs, files in os.walk(destination_dir):\n",
    "    level = root.replace(destination_dir, '').count(os.sep)\n",
    "    indent = ' ' * 4 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 4 * (level + 1)\n",
    "    for f in files:\n",
    "        print(f\"{subindent}{f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415101c1",
   "metadata": {
    "papermill": {
     "duration": 0.076154,
     "end_time": "2024-10-21T19:10:31.486897",
     "exception": false,
     "start_time": "2024-10-21T19:10:31.410743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration for 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438ea05c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T19:10:31.684403Z",
     "iopub.status.busy": "2024-10-21T19:10:31.684027Z",
     "iopub.status.idle": "2024-10-21T19:10:39.313357Z",
     "shell.execute_reply": "2024-10-21T19:10:39.312144Z"
    },
    "papermill": {
     "duration": 7.708644,
     "end_time": "2024-10-21T19:10:39.315471",
     "exception": false,
     "start_time": "2024-10-21T19:10:31.606827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file saved at: /kaggle/working/create_config/Semantic_Segmentation_2Epochs_NewDataset_Unet.yaml\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 10\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-new/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: ''\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Semantic_Segmentation_2Epochs_NewDataset_Unet\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_models\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  MODEL: U-Net\n",
      "  NUM_CLASSES_MATERIAL: 5\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0002\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dlcv.utils import create_config\n",
    "#this function from utils.py takes the following arguments\n",
    "run_name = 'Semantic_Segmentation_2Epochs_NewDataset_Unet'\n",
    "root = '/kaggle/input/material-dataset-new/Material_dataset'\n",
    "\n",
    "# Choose a Backbone for the FasterRCNN Model\n",
    "model = 'U-Net'\n",
    "backbone = 'mobilenet'   # (Options- 'resnet50', 'resnet101', 'mobilenet')\n",
    "\n",
    "# Scheduler and Optimizer Hyper-Parameters.\n",
    "base_lr = 0.0002  # Learning Rate\n",
    "milestones = [10, 20]\n",
    "gamma = 0.1\n",
    "\n",
    "# Training Hyper-Parameters\n",
    "batch_size = 8          #(Resnet50: 4, Resnet101: 2, MobileNet: 8)\n",
    "num_epochs = 2         #(Avg. Time per Epoch: Resnet50- 4:20, Resnet101- 5:45, Mobilenet: 3:43 )\n",
    "early_stopping = False\n",
    "\n",
    "# Augmentation Parameters\n",
    "horizontal_flip_prob = 0.5\n",
    "rotation_degrees = 10\n",
    "crop_size = [256,256]\n",
    "pretrained_weights= ''#'/kaggle/input/deeplabv3plus_semanticsegmentation_newdataset/pytorch/50epochs/1/Semantic_Segmentation_50Epochs_NewDataset.pth'\n",
    "save_path = '/kaggle/working/saved_models'\n",
    "\n",
    "config_file_path = create_config(run_name, model, backbone, base_lr,\n",
    "                                 batch_size, num_epochs, horizontal_flip_prob,\n",
    "                                rotation_degrees, crop_size, milestones, gamma, \n",
    "                                early_stopping, pretrained_weights, save_path, root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd673790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T19:10:39.470637Z",
     "iopub.status.busy": "2024-10-21T19:10:39.470137Z",
     "iopub.status.idle": "2024-10-21T19:10:39.474606Z",
     "shell.execute_reply": "2024-10-21T19:10:39.473766Z"
    },
    "papermill": {
     "duration": 0.08343,
     "end_time": "2024-10-21T19:10:39.476417",
     "exception": false,
     "start_time": "2024-10-21T19:10:39.392987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Path to the config file you want to use\n",
    "#config_file = 'config_kaggle.yaml'#yaml file name here\n",
    "#config_file_path = '/kaggle/working/repository_content/config/' + config_file\n",
    "os.environ['CONFIG_FILE'] = config_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa045ce2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T19:10:39.632195Z",
     "iopub.status.busy": "2024-10-21T19:10:39.631397Z",
     "iopub.status.idle": "2024-10-21T19:21:25.389428Z",
     "shell.execute_reply": "2024-10-21T19:21:25.388458Z"
    },
    "papermill": {
     "duration": 645.838101,
     "end_time": "2024-10-21T19:21:25.391487",
     "exception": false,
     "start_time": "2024-10-21T19:10:39.553386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/material_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
      "  0%|          | 0.00/13.6M [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using configuration file: /kaggle/working/create_config/Semantic_Segmentation_2Epochs_NewDataset_Unet.yaml\n",
      "Configuration for this run:\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 10\n",
      "CONFIG_FILE_PATH: /kaggle/working/create_config/Semantic_Segmentation_2Epochs_NewDataset_Unet.yaml\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-new/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: ''\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Semantic_Segmentation_2Epochs_NewDataset_Unet\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_models\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  MODEL: U-Net\n",
      "  NUM_CLASSES_MATERIAL: 5\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0002\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 2\n",
      "\n",
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 82.9MB/s]\n",
      "Training U-Net:   0%|          | 0/2000 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Training U-Net: 100%|██████████| 2000/2000 [04:52<00:00,  6.84it/s]\n",
      "Evaluation U-Net: 100%|██████████| 500/500 [01:39<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Train Loss: 0.4934, Test Loss: 0.4069, Test IoU: 0.3587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training U-Net: 100%|██████████| 2000/2000 [02:36<00:00, 12.76it/s]\n",
      "Evaluation U-Net: 100%|██████████| 500/500 [00:56<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Train Loss: 0.6003, Test Loss: 0.5702, Test IoU: 0.3176\n",
      "Train Loss: 0.6003, Test Loss: 0.5702, Test IoU (Material): 0.3176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'repository_content/train.py', '--config', '/kaggle/working/create_config/Semantic_Segmentation_2Epochs_NewDataset_Unet.yaml', '--mode', 'train'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from dlcv.train import main as train_main\n",
    "from dlcv.config import get_cfg_defaults\n",
    "cfg = get_cfg_defaults()\n",
    "print(cfg.DATA.MATERIAL_ROOT)\n",
    "subprocess.run(['python', 'repository_content/train.py', '--config', config_file_path, '--mode', 'train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f44f65e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T19:21:25.834316Z",
     "iopub.status.busy": "2024-10-21T19:21:25.833943Z",
     "iopub.status.idle": "2024-10-21T19:21:25.845561Z",
     "shell.execute_reply": "2024-10-21T19:21:25.844748Z"
    },
    "papermill": {
     "duration": 0.235097,
     "end_time": "2024-10-21T19:21:25.847784",
     "exception": false,
     "start_time": "2024-10-21T19:21:25.612687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file saved at: /kaggle/working/create_config/Visualization_100Epochs.yaml\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 10\n",
      "  - 20\n",
      "  HORIZONTAL_FLIP_PROB: 11\n",
      "  ROTATION_DEGREES:\n",
      "  - 256\n",
      "  - 256\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-new/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: /kaggle/working/saved_prediction\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Visualization_100Epochs\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: ''\n",
      "MODEL:\n",
      "  BACKBONE: 0.0005\n",
      "  MODEL: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 5\n",
      "TRAIN:\n",
      "  BASE_LR: 8\n",
      "  BATCH_SIZE: 1\n",
      "  EARLY_STOPPING: /kaggle/input/deeplabv3plus_semanticsegmentation_newdataset/pytorch/50epochs/1/Semantic_Segmentation_50Epochs_NewDataset.pth\n",
      "  GAMMA: false\n",
      "  MILESTONES: 0.1\n",
      "  NUM_EPOCHS: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#this function from utils.py takes the following arguments\n",
    "from dlcv.utils import create_config\n",
    "run_name = 'Visualization_100Epochs'\n",
    "\n",
    "# Choose a Backbone for the FasterRCNN Model\n",
    "backbone = 'mobilenet'   # (Options- 'resnet50', 'resnet101', 'mobilenet')\n",
    "\n",
    "# Scheduler and Optimizer Hyper-Parameters.\n",
    "base_lr = 0.0005  # Learning Rate\n",
    "milestones = [10, 20]\n",
    "gamma = 0.1\n",
    "\n",
    "# Training Hyper-Parameters\n",
    "batch_size = 8          #(Resnet50: 4, Resnet101: 2, MobileNet: 8)\n",
    "num_epochs = 1         #(Avg. Time per Epoch: Resnet50- 4:20, Resnet101- 5:45, Mobilenet: 3:43 )\n",
    "early_stopping = False\n",
    "\n",
    "# Augmentation Parameters\n",
    "horizontal_flip_prob = 0.5\n",
    "rotation_degrees = 11\n",
    "crop_size = [256,256]\n",
    "\n",
    "pretrained_weights= '/kaggle/input/deeplabv3plus_semanticsegmentation_newdataset/pytorch/50epochs/1/Semantic_Segmentation_50Epochs_NewDataset.pth'\n",
    "save_path = '/kaggle/working/saved_prediction'\n",
    "config_file_path = create_config(run_name, backbone, base_lr,\n",
    "                                 batch_size, num_epochs, horizontal_flip_prob,\n",
    "                                rotation_degrees, crop_size, milestones, gamma,\n",
    "                                early_stopping, pretrained_weights, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "625bf3a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T19:21:26.314159Z",
     "iopub.status.busy": "2024-10-21T19:21:26.313158Z",
     "iopub.status.idle": "2024-10-21T19:21:32.567950Z",
     "shell.execute_reply": "2024-10-21T19:21:32.567007Z"
    },
    "papermill": {
     "duration": 6.502019,
     "end_time": "2024-10-21T19:21:32.570275",
     "exception": false,
     "start_time": "2024-10-21T19:21:26.068256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/working/repository_content/train.py\", line 159, in <module>\n",
      "    cfg.merge_from_file(config_file_path)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/yacs/config.py\", line 213, in merge_from_file\n",
      "    self.merge_from_other_cfg(cfg)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/yacs/config.py\", line 217, in merge_from_other_cfg\n",
      "    _merge_a_into_b(cfg_other, self, self, [])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/yacs/config.py\", line 478, in _merge_a_into_b\n",
      "    _merge_a_into_b(v, b[k], root, key_list + [k])\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/yacs/config.py\", line 474, in _merge_a_into_b\n",
      "    v = _check_and_coerce_cfg_value_type(v, b[k], k, full_key)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/yacs/config.py\", line 534, in _check_and_coerce_cfg_value_type\n",
      "    raise ValueError(\n",
      "ValueError: Type mismatch (<class 'float'> vs. <class 'int'>) with values (0.5 vs. 11) for config key: AUGMENTATION.HORIZONTAL_FLIP_PROB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'repository_content/train.py', '--config', '/kaggle/working/create_config/Visualization_100Epochs.yaml', '--mode', 'single_image', '--image_path', '/kaggle/working/repository_content/images/airplane.jpg'], returncode=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run(['python', 'repository_content/train.py', '--config', config_file_path, '--mode', 'single_image', '--image_path', '/kaggle/working/repository_content/images/airplane.jpg'])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5908856,
     "sourceId": 9669620,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 142719,
     "modelInstanceId": 119473,
     "sourceId": 141051,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 825.087957,
   "end_time": "2024-10-21T19:21:33.920451",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-21T19:07:48.832494",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
