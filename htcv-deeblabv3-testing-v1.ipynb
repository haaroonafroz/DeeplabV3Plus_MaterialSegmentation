{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547716d1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-20T09:58:32.243242Z",
     "iopub.status.busy": "2024-10-20T09:58:32.242941Z",
     "iopub.status.idle": "2024-10-20T10:01:08.866240Z",
     "shell.execute_reply": "2024-10-20T10:01:08.865061Z"
    },
    "papermill": {
     "duration": 156.630468,
     "end_time": "2024-10-20T10:01:08.868697",
     "exception": false,
     "start_time": "2024-10-20T09:58:32.238229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git\r\n",
      "  Cloning https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git to /tmp/pip-req-build-7yvmri0o\r\n",
      "  Running command git clone --filter=blob:none --quiet 'https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git' /tmp/pip-req-build-7yvmri0o\r\n",
      "  Resolved https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git to commit 457ce4541733fc928c5c6e52d7b3ca1c72e09343\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (8.1.1)\r\n",
      "Collecting torch==2.3.0 (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "Collecting torchvision==0.18.0 (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\r\n",
      "Collecting torchaudio==2.3.0 (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.66.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.7.5)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.2.2)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.22.0)\r\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.12.2)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (6.0.1)\r\n",
      "Collecting yacs (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\r\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.26.4)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.9.0.80)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2024.2.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.3.0 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.18.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (9.5.0)\r\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.9.0.post0)\r\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.0.0)\r\n",
      "Requirement already satisfied: pluggy<2.0,>=1.4 in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.4.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.2.0)\r\n",
      "Requirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.0.1)\r\n",
      "Requirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.11.4)\r\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.33.1)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2023.12.9)\r\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.4.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.2.0)\r\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.10/site-packages (from seaborn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.1.4)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2023.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.3.0)\r\n",
      "Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\r\n",
      "Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: HTCV_DeeplabV3Plus_MaterialSegmentation\r\n",
      "  Building wheel for HTCV_DeeplabV3Plus_MaterialSegmentation (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for HTCV_DeeplabV3Plus_MaterialSegmentation: filename=HTCV_DeeplabV3Plus_MaterialSegmentation-0.0.1-py3-none-any.whl size=5844587 sha256=153b80e11e1fbb76e93689a3909c0e6901d9a27fa46392cdb1e9a618f7c6e758\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-38xj9es5/wheels/3a/dd/47/f7229c606648c55ebb6dd9026436f12245ae6107f066c04dc8\r\n",
      "Successfully built HTCV_DeeplabV3Plus_MaterialSegmentation\r\n",
      "Installing collected packages: yacs, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio, HTCV_DeeplabV3Plus_MaterialSegmentation\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.1.2\r\n",
      "    Uninstalling torch-2.1.2:\r\n",
      "      Successfully uninstalled torch-2.1.2\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.16.2\r\n",
      "    Uninstalling torchvision-0.16.2:\r\n",
      "      Successfully uninstalled torchvision-0.16.2\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 2.1.2\r\n",
      "    Uninstalling torchaudio-2.1.2:\r\n",
      "      Successfully uninstalled torchaudio-2.1.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.7.14 requires torch<2.3,>=1.10, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed HTCV_DeeplabV3Plus_MaterialSegmentation-0.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 torchaudio-2.3.0 torchvision-0.18.0 triton-2.3.0 yacs-0.1.8\r\n"
     ]
    }
   ],
   "source": [
    "token = \"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\"#token here\n",
    "user = \"haaroonafroz\" #username here\n",
    "repo_name = \"DeeplabV3Plus_MaterialSegmentation\" #repository name here\n",
    "url = f\"https://{user}:{token}@github.com/{user}/{repo_name}.git\"\n",
    "\n",
    "!pip install git+{url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "645de4cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T10:01:09.020920Z",
     "iopub.status.busy": "2024-10-20T10:01:09.020526Z",
     "iopub.status.idle": "2024-10-20T10:01:09.045972Z",
     "shell.execute_reply": "2024-10-20T10:01:09.044801Z"
    },
    "papermill": {
     "duration": 0.105838,
     "end_time": "2024-10-20T10:01:09.048146",
     "exception": false,
     "start_time": "2024-10-20T10:01:08.942308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repository_content/\n",
      "    plot.py\n",
      "    train.py\n",
      "    config.py\n",
      "    visualize.py\n",
      "    model.py\n",
      "    __init__.py\n",
      "    utils.py\n",
      "    training.py\n",
      "    dataset.py\n",
      "    __pycache__/\n",
      "        visualize.cpython-310.pyc\n",
      "        config.cpython-310.pyc\n",
      "        train.cpython-310.pyc\n",
      "        dataset.cpython-310.pyc\n",
      "        plot.cpython-310.pyc\n",
      "        model.cpython-310.pyc\n",
      "        training.cpython-310.pyc\n",
      "        utils.cpython-310.pyc\n",
      "        __init__.cpython-310.pyc\n",
      "    config/\n",
      "        config_kaggle.yaml\n",
      "        config2.yaml\n",
      "        config1.yaml\n",
      "        config3.yaml\n",
      "    predictions/\n",
      "        Bunny_scene_confidence_maps.png\n",
      "        bicycle_prediction.png\n",
      "        airplane_confidence_maps.png\n",
      "        boat_confidence_maps.png\n",
      "        airplane_prediction.png\n",
      "        boat_segmentation_with_boundaries.png\n",
      "        bicycle_confidence_maps_Kaggle.png\n",
      "        boat_prediction.png\n",
      "        Confidence_heatmap_airplane.png\n",
      "        airplane_confidence_maps_Kaggle.png\n",
      "        boat_confidence_maps_boat_kaggle.png\n",
      "        image_0036_m_prediction.png\n",
      "        airplane_segmentation_with_boundaries.png\n",
      "    images/\n",
      "        chair_wood.jpg\n",
      "        Bunny_scene.jpg\n",
      "        bicycle.jpg\n",
      "        airplane.jpg\n",
      "        boat.jpg\n",
      "        chair_wood_blackbg.jpg\n",
      "        person_dog.jpg\n",
      "        chair_wood_blackbg1.jpg\n",
      "        .gitkeep\n",
      "        bottle_glass_blackbg.jpg\n",
      "    saved_models/\n",
      "        fixture_weights_dont_delete_this.pth\n",
      "        test_model.pth\n",
      "        underfitting_run.pth\n",
      "    results/\n",
      "        .gitkeep\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import dlcv  # Assuming the repository is installed and accessible as a Python package\n",
    "\n",
    "# Determine the source directory from the installed package location\n",
    "source_dir = os.path.dirname(dlcv.__file__)\n",
    "destination_dir = os.path.join(os.getcwd(), 'repository_content')\n",
    "\n",
    "# Create the destination directory\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Copy contents from the source directory to the destination directory\n",
    "for item in os.listdir(source_dir):\n",
    "    source_item = os.path.join(source_dir, item)\n",
    "    destination_item = os.path.join(destination_dir, item)\n",
    "    if os.path.isdir(source_item):\n",
    "        shutil.copytree(source_item, destination_item, dirs_exist_ok=True)\n",
    "    else:\n",
    "        shutil.copy2(source_item, destination_item)\n",
    "\n",
    "# List the contents of the destination directory\n",
    "for root, dirs, files in os.walk(destination_dir):\n",
    "    level = root.replace(destination_dir, '').count(os.sep)\n",
    "    indent = ' ' * 4 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 4 * (level + 1)\n",
    "    for f in files:\n",
    "        print(f\"{subindent}{f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9a689b",
   "metadata": {
    "papermill": {
     "duration": 0.073436,
     "end_time": "2024-10-20T10:01:09.195305",
     "exception": false,
     "start_time": "2024-10-20T10:01:09.121869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration for 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f63fd7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T10:01:09.388213Z",
     "iopub.status.busy": "2024-10-20T10:01:09.387613Z",
     "iopub.status.idle": "2024-10-20T10:01:17.255962Z",
     "shell.execute_reply": "2024-10-20T10:01:17.254936Z"
    },
    "papermill": {
     "duration": 7.944836,
     "end_time": "2024-10-20T10:01:17.258120",
     "exception": false,
     "start_time": "2024-10-20T10:01:09.313284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file saved at: /kaggle/working/create_config/Semantic_Segmentation_50Epochs_NewDataset.yaml\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 10\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-new/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: /kaggle/input/deeplabv3plus_semanticsegmentation_newdataset/pytorch/50epochs/1/Semantic_Segmentation_50Epochs_NewDataset.pth\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Semantic_Segmentation_50Epochs_NewDataset\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_models\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 5\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0002\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dlcv.utils import create_config\n",
    "#this function from utils.py takes the following arguments\n",
    "run_name = 'Semantic_Segmentation_50Epochs_NewDataset'\n",
    "root = '/kaggle/input/material-dataset-new/Material_dataset'\n",
    "\n",
    "# Choose a Backbone for the FasterRCNN Model\n",
    "backbone = 'mobilenet'   # (Options- 'resnet50', 'resnet101', 'mobilenet')\n",
    "\n",
    "# Scheduler and Optimizer Hyper-Parameters.\n",
    "base_lr = 0.0002  # Learning Rate\n",
    "milestones = [10, 20]\n",
    "gamma = 0.1\n",
    "\n",
    "# Training Hyper-Parameters\n",
    "batch_size = 8          #(Resnet50: 4, Resnet101: 2, MobileNet: 8)\n",
    "num_epochs = 50         #(Avg. Time per Epoch: Resnet50- 4:20, Resnet101- 5:45, Mobilenet: 3:43 )\n",
    "early_stopping = False\n",
    "\n",
    "# Augmentation Parameters\n",
    "horizontal_flip_prob = 0.5\n",
    "rotation_degrees = 10\n",
    "crop_size = [256,256]\n",
    "pretrained_weights= '/kaggle/input/deeplabv3plus_semanticsegmentation_newdataset/pytorch/50epochs/1/Semantic_Segmentation_50Epochs_NewDataset.pth'\n",
    "save_path = '/kaggle/working/saved_models'\n",
    "\n",
    "config_file_path = create_config(run_name, backbone, base_lr,\n",
    "                                 batch_size, num_epochs, horizontal_flip_prob,\n",
    "                                rotation_degrees, crop_size, milestones, gamma, \n",
    "                                early_stopping, pretrained_weights, save_path, root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33400e61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T10:01:17.423145Z",
     "iopub.status.busy": "2024-10-20T10:01:17.422248Z",
     "iopub.status.idle": "2024-10-20T10:01:17.427666Z",
     "shell.execute_reply": "2024-10-20T10:01:17.426637Z"
    },
    "papermill": {
     "duration": 0.096181,
     "end_time": "2024-10-20T10:01:17.430034",
     "exception": false,
     "start_time": "2024-10-20T10:01:17.333853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Path to the config file you want to use\n",
    "#config_file = 'config_kaggle.yaml'#yaml file name here\n",
    "#config_file_path = '/kaggle/working/repository_content/config/' + config_file\n",
    "os.environ['CONFIG_FILE'] = config_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1867b97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T10:01:17.608077Z",
     "iopub.status.busy": "2024-10-20T10:01:17.607704Z",
     "iopub.status.idle": "2024-10-20T18:02:17.469655Z",
     "shell.execute_reply": "2024-10-20T18:02:17.468509Z"
    },
    "papermill": {
     "duration": 28862.839801,
     "end_time": "2024-10-20T18:02:20.356403",
     "exception": false,
     "start_time": "2024-10-20T10:01:17.516602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/material_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 102MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using configuration file: /kaggle/working/create_config/Semantic_Segmentation_50Epochs_NewDataset.yaml\n",
      "Configuration for this run:\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 10\n",
      "CONFIG_FILE_PATH: /kaggle/working/create_config/Semantic_Segmentation_50Epochs_NewDataset.yaml\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-new/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: /kaggle/input/deeplabv3plus_semanticsegmentation_newdataset/pytorch/50epochs/1/Semantic_Segmentation_50Epochs_NewDataset.pth\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Semantic_Segmentation_50Epochs_NewDataset\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_models\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 5\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0002\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 50\n",
      "\n",
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Training: 100%|██████████| 2000/2000 [08:51<00:00,  3.76it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:37<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.5177, Test Loss: 0.0889, Test IoU (Material): 0.2843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:27<00:00,  3.94it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Train Loss: 0.3880, Test Loss: 0.7752, Test IoU (Material): 0.1311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [07:14<00:00,  4.60it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Train Loss: 0.4887, Test Loss: 1.1713, Test IoU (Material): 0.2384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:04<00:00,  4.13it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Train Loss: 0.4447, Test Loss: -0.3151, Test IoU (Material): 0.2522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:12<00:00,  4.06it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Train Loss: 0.4935, Test Loss: 0.5020, Test IoU (Material): 0.1828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:31<00:00,  3.91it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Train Loss: 0.4365, Test Loss: 0.4513, Test IoU (Material): 0.0933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:36<00:00,  3.87it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Train Loss: 0.5007, Test Loss: 0.5299, Test IoU (Material): 0.1721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:41<00:00,  3.83it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Train Loss: 0.4268, Test Loss: 1.2577, Test IoU (Material): 0.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:48<00:00,  3.79it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Train Loss: 0.5192, Test Loss: 0.4939, Test IoU (Material): 0.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [07:59<00:00,  4.17it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Train Loss: 0.4679, Test Loss: 0.6831, Test IoU (Material): 0.1769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:51<00:00,  3.76it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Train Loss: 0.5814, Test Loss: -2.8667, Test IoU (Material): 0.2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:48<00:00,  3.78it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Train Loss: 0.5615, Test Loss: 0.5232, Test IoU (Material): 0.1745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:24<00:00,  3.96it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Train Loss: 0.6446, Test Loss: 2.3555, Test IoU (Material): 0.2660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [07:54<00:00,  4.21it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Train Loss: 0.4379, Test Loss: 2.8547, Test IoU (Material): 0.1364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [07:49<00:00,  4.26it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Train Loss: 0.5444, Test Loss: 0.7002, Test IoU (Material): 0.1304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [07:46<00:00,  4.29it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Train Loss: 0.7065, Test Loss: 0.5550, Test IoU (Material): 0.2818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:18<00:00,  4.01it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Train Loss: 0.5272, Test Loss: 0.3453, Test IoU (Material): 0.3468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:41<00:00,  3.83it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:28<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Train Loss: 0.5368, Test Loss: 0.4740, Test IoU (Material): 0.3520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:58<00:00,  3.71it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Train Loss: 0.4202, Test Loss: 0.3264, Test IoU (Material): 0.2927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [07:55<00:00,  4.20it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Train Loss: 0.5193, Test Loss: 0.7904, Test IoU (Material): 0.2856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [07:50<00:00,  4.25it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Train Loss: 0.5513, Test Loss: 0.4075, Test IoU (Material): 0.3036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:44<00:00,  7.02it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:24<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Train Loss: 0.6746, Test Loss: 0.5445, Test IoU (Material): 0.3154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [03:55<00:00,  8.50it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Train Loss: 0.5814, Test Loss: 0.4149, Test IoU (Material): 0.3127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:28<00:00,  7.44it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Train Loss: 0.5690, Test Loss: 0.0440, Test IoU (Material): 0.3230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:15<00:00,  7.81it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Train Loss: 0.5661, Test Loss: 0.6642, Test IoU (Material): 0.3222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [05:42<00:00,  5.83it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Train Loss: 0.4892, Test Loss: 0.5295, Test IoU (Material): 0.3315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [07:17<00:00,  4.57it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Train Loss: -3.3392, Test Loss: 0.7741, Test IoU (Material): 0.3095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [06:10<00:00,  5.40it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Train Loss: 0.0351, Test Loss: 0.7784, Test IoU (Material): 0.3143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:50<00:00,  6.88it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Train Loss: 3.2323, Test Loss: 0.4853, Test IoU (Material): 0.3107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:48<00:00,  6.93it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Train Loss: 32.1000, Test Loss: 19.5712, Test IoU (Material): 0.3126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:09<00:00,  8.03it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Train Loss: 1.9367, Test Loss: -3.6659, Test IoU (Material): 0.3101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:04<00:00,  8.17it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Train Loss: 0.9932, Test Loss: -6.7402, Test IoU (Material): 0.3026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [03:59<00:00,  8.36it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Train Loss: 0.6795, Test Loss: 0.3751, Test IoU (Material): 0.3060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:02<00:00,  8.23it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:27<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Train Loss: 1.0181, Test Loss: 0.3734, Test IoU (Material): 0.3179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [03:56<00:00,  8.46it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Train Loss: 0.8593, Test Loss: 0.0186, Test IoU (Material): 0.3078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:15<00:00,  7.84it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Train Loss: 0.8311, Test Loss: 1.8173, Test IoU (Material): 0.2983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:11<00:00,  7.96it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Train Loss: 4.0440, Test Loss: 0.4382, Test IoU (Material): 0.3079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:21<00:00,  7.64it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Train Loss: -0.8819, Test Loss: 0.3988, Test IoU (Material): 0.3024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:18<00:00,  7.74it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Train Loss: 0.5210, Test Loss: 0.1520, Test IoU (Material): 0.3021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:20<00:00,  7.69it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Train Loss: 1.3055, Test Loss: 0.4372, Test IoU (Material): 0.3084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:07<00:00,  8.09it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Train Loss: 0.4202, Test Loss: 1.1178, Test IoU (Material): 0.3080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [03:58<00:00,  8.40it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Train Loss: 0.0511, Test Loss: 0.5276, Test IoU (Material): 0.3132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [03:55<00:00,  8.51it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Train Loss: 0.4595, Test Loss: 0.3353, Test IoU (Material): 0.3192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [03:53<00:00,  8.58it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Train Loss: 0.9480, Test Loss: 0.4554, Test IoU (Material): 0.3183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [03:58<00:00,  8.39it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Train Loss: 1.0055, Test Loss: 0.3756, Test IoU (Material): 0.3119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:19<00:00,  7.70it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Train Loss: 0.7538, Test Loss: 0.5065, Test IoU (Material): 0.3108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:07<00:00,  8.08it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Train Loss: -0.4547, Test Loss: 1.3476, Test IoU (Material): 0.3163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:03<00:00,  8.20it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Train Loss: -0.2593, Test Loss: -10.4965, Test IoU (Material): 0.3148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:10<00:00,  7.98it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Train Loss: -0.4753, Test Loss: 0.6021, Test IoU (Material): 0.3098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:06<00:00,  8.11it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Train Loss: 0.3001, Test Loss: 0.2356, Test IoU (Material): 0.3144\n",
      "Train Loss: 0.3001, Test Loss: 0.2356, Test IoU (Material): 0.3144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'repository_content/train.py', '--config', '/kaggle/working/create_config/Semantic_Segmentation_50Epochs_NewDataset.yaml', '--mode', 'train'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from dlcv.train import main as train_main\n",
    "from dlcv.config import get_cfg_defaults\n",
    "cfg = get_cfg_defaults()\n",
    "print(cfg.DATA.MATERIAL_ROOT)\n",
    "subprocess.run(['python', 'repository_content/train.py', '--config', config_file_path, '--mode', 'train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051f9902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T18:02:33.975374Z",
     "iopub.status.busy": "2024-10-20T18:02:33.974951Z",
     "iopub.status.idle": "2024-10-20T18:02:33.988647Z",
     "shell.execute_reply": "2024-10-20T18:02:33.987613Z"
    },
    "papermill": {
     "duration": 6.744791,
     "end_time": "2024-10-20T18:02:33.990686",
     "exception": false,
     "start_time": "2024-10-20T18:02:27.245895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file saved at: /kaggle/working/create_config/Visualization_100Epochs.yaml\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 11\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-new/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: /kaggle/input/deeplabv3plus_semanticsegmentation_newdataset/pytorch/50epochs/1/Semantic_Segmentation_50Epochs_NewDataset.pth\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Visualization_100Epochs\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_prediction\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 5\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0005\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#this function from utils.py takes the following arguments\n",
    "from dlcv.utils import create_config\n",
    "run_name = 'Visualization_100Epochs'\n",
    "\n",
    "# Choose a Backbone for the FasterRCNN Model\n",
    "backbone = 'mobilenet'   # (Options- 'resnet50', 'resnet101', 'mobilenet')\n",
    "\n",
    "# Scheduler and Optimizer Hyper-Parameters.\n",
    "base_lr = 0.0005  # Learning Rate\n",
    "milestones = [10, 20]\n",
    "gamma = 0.1\n",
    "\n",
    "# Training Hyper-Parameters\n",
    "batch_size = 8          #(Resnet50: 4, Resnet101: 2, MobileNet: 8)\n",
    "num_epochs = 1         #(Avg. Time per Epoch: Resnet50- 4:20, Resnet101- 5:45, Mobilenet: 3:43 )\n",
    "early_stopping = False\n",
    "\n",
    "# Augmentation Parameters\n",
    "horizontal_flip_prob = 0.5\n",
    "rotation_degrees = 11\n",
    "crop_size = [256,256]\n",
    "\n",
    "pretrained_weights= '/kaggle/input/deeplabv3plus_semanticsegmentation_newdataset/pytorch/50epochs/1/Semantic_Segmentation_50Epochs_NewDataset.pth'\n",
    "save_path = '/kaggle/working/saved_prediction'\n",
    "config_file_path = create_config(run_name, backbone, base_lr,\n",
    "                                 batch_size, num_epochs, horizontal_flip_prob,\n",
    "                                rotation_degrees, crop_size, milestones, gamma,\n",
    "                                early_stopping, pretrained_weights, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55fc68e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T18:02:47.277950Z",
     "iopub.status.busy": "2024-10-20T18:02:47.277521Z",
     "iopub.status.idle": "2024-10-20T18:03:01.043919Z",
     "shell.execute_reply": "2024-10-20T18:03:01.042562Z"
    },
    "papermill": {
     "duration": 20.384579,
     "end_time": "2024-10-20T18:03:01.046275",
     "exception": false,
     "start_time": "2024-10-20T18:02:40.661696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using configuration file: /kaggle/working/create_config/Visualization_100Epochs.yaml\n",
      "Configuration for this run:\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 11\n",
      "CONFIG_FILE_PATH: /kaggle/working/create_config/Visualization_100Epochs.yaml\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-new/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: /kaggle/input/deeplabv3plus_semanticsegmentation_newdataset/pytorch/50epochs/1/Semantic_Segmentation_50Epochs_NewDataset.pth\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Visualization_100Epochs\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_prediction\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 5\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0005\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 1\n",
      "\n",
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'repository_content/train.py', '--config', '/kaggle/working/create_config/Visualization_100Epochs.yaml', '--mode', 'single_image', '--image_path', '/kaggle/working/repository_content/images/airplane.jpg'], returncode=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run(['python', 'repository_content/train.py', '--config', config_file_path, '--mode', 'single_image', '--image_path', '/kaggle/working/repository_content/images/airplane.jpg'])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5908856,
     "sourceId": 9669620,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 142719,
     "modelInstanceId": 119473,
     "sourceId": 141051,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29079.547723,
   "end_time": "2024-10-20T18:03:09.036230",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-20T09:58:29.488507",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
