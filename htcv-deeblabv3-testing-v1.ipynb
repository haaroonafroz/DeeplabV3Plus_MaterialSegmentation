{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae8a50e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-15T20:46:04.276837Z",
     "iopub.status.busy": "2024-10-15T20:46:04.276418Z",
     "iopub.status.idle": "2024-10-15T20:48:46.001078Z",
     "shell.execute_reply": "2024-10-15T20:48:45.999870Z"
    },
    "papermill": {
     "duration": 161.732137,
     "end_time": "2024-10-15T20:48:46.003778",
     "exception": false,
     "start_time": "2024-10-15T20:46:04.271641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git\r\n",
      "  Cloning https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git to /tmp/pip-req-build-h2tg3wea\r\n",
      "  Running command git clone --filter=blob:none --quiet 'https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git' /tmp/pip-req-build-h2tg3wea\r\n",
      "  Resolved https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git to commit d65f620a25f8ee2c8a160cf6b505e749ff16f697\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (8.1.1)\r\n",
      "Collecting torch==2.3.0 (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "Collecting torchvision==0.18.0 (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\r\n",
      "Collecting torchaudio==2.3.0 (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.66.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.7.5)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.2.2)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.22.0)\r\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.12.2)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (6.0.1)\r\n",
      "Collecting yacs (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\r\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.26.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2024.2.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.3.0 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.18.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (9.5.0)\r\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.9.0.post0)\r\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.0.0)\r\n",
      "Requirement already satisfied: pluggy<2.0,>=1.4 in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.4.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.2.0)\r\n",
      "Requirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.0.1)\r\n",
      "Requirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.11.4)\r\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.33.1)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2023.12.9)\r\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.4.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.2.0)\r\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.10/site-packages (from seaborn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.1.4)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2023.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.3.0)\r\n",
      "Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\r\n",
      "Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: HTCV_DeeplabV3Plus_MaterialSegmentation\r\n",
      "  Building wheel for HTCV_DeeplabV3Plus_MaterialSegmentation (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for HTCV_DeeplabV3Plus_MaterialSegmentation: filename=HTCV_DeeplabV3Plus_MaterialSegmentation-0.0.1-py3-none-any.whl size=966955 sha256=380009c44175b569eeffeac15bc50441d508808a454aecea0ad3833dd824f8b0\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-lus01wto/wheels/3a/dd/47/f7229c606648c55ebb6dd9026436f12245ae6107f066c04dc8\r\n",
      "Successfully built HTCV_DeeplabV3Plus_MaterialSegmentation\r\n",
      "Installing collected packages: yacs, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio, HTCV_DeeplabV3Plus_MaterialSegmentation\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.1.2\r\n",
      "    Uninstalling torch-2.1.2:\r\n",
      "      Successfully uninstalled torch-2.1.2\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.16.2\r\n",
      "    Uninstalling torchvision-0.16.2:\r\n",
      "      Successfully uninstalled torchvision-0.16.2\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 2.1.2\r\n",
      "    Uninstalling torchaudio-2.1.2:\r\n",
      "      Successfully uninstalled torchaudio-2.1.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.7.14 requires torch<2.3,>=1.10, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed HTCV_DeeplabV3Plus_MaterialSegmentation-0.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 torchaudio-2.3.0 torchvision-0.18.0 triton-2.3.0 yacs-0.1.8\r\n"
     ]
    }
   ],
   "source": [
    "token = \"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\"#token here\n",
    "user = \"haaroonafroz\" #username here\n",
    "repo_name = \"DeeplabV3Plus_MaterialSegmentation\" #repository name here\n",
    "url = f\"https://{user}:{token}@github.com/{user}/{repo_name}.git\"\n",
    "\n",
    "!pip install git+{url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd78051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:48:46.166869Z",
     "iopub.status.busy": "2024-10-15T20:48:46.166432Z",
     "iopub.status.idle": "2024-10-15T20:48:46.186006Z",
     "shell.execute_reply": "2024-10-15T20:48:46.184795Z"
    },
    "papermill": {
     "duration": 0.101379,
     "end_time": "2024-10-15T20:48:46.188195",
     "exception": false,
     "start_time": "2024-10-15T20:48:46.086816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repository_content/\n",
      "    utils.py\n",
      "    dataset.py\n",
      "    plot.py\n",
      "    config.py\n",
      "    visualize.py\n",
      "    model.py\n",
      "    training.py\n",
      "    train.py\n",
      "    __init__.py\n",
      "    saved_models/\n",
      "        test_model.pth\n",
      "        fixture_weights_dont_delete_this.pth\n",
      "        underfitting_run.pth\n",
      "    images/\n",
      "        airplane.jpg\n",
      "        person_dog.jpg\n",
      "        bicycle.jpg\n",
      "        .gitkeep\n",
      "        Bunny_scene.jpg\n",
      "        boat.jpg\n",
      "    __pycache__/\n",
      "        config.cpython-310.pyc\n",
      "        dataset.cpython-310.pyc\n",
      "        model.cpython-310.pyc\n",
      "        train.cpython-310.pyc\n",
      "        visualize.cpython-310.pyc\n",
      "        utils.cpython-310.pyc\n",
      "        training.cpython-310.pyc\n",
      "        plot.cpython-310.pyc\n",
      "        __init__.cpython-310.pyc\n",
      "    config/\n",
      "        config1.yaml\n",
      "        config2.yaml\n",
      "        config3.yaml\n",
      "        config_kaggle.yaml\n",
      "    results/\n",
      "        .gitkeep\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import dlcv  # Assuming the repository is installed and accessible as a Python package\n",
    "\n",
    "# Determine the source directory from the installed package location\n",
    "source_dir = os.path.dirname(dlcv.__file__)\n",
    "destination_dir = os.path.join(os.getcwd(), 'repository_content')\n",
    "\n",
    "# Create the destination directory\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Copy contents from the source directory to the destination directory\n",
    "for item in os.listdir(source_dir):\n",
    "    source_item = os.path.join(source_dir, item)\n",
    "    destination_item = os.path.join(destination_dir, item)\n",
    "    if os.path.isdir(source_item):\n",
    "        shutil.copytree(source_item, destination_item, dirs_exist_ok=True)\n",
    "    else:\n",
    "        shutil.copy2(source_item, destination_item)\n",
    "\n",
    "# List the contents of the destination directory\n",
    "for root, dirs, files in os.walk(destination_dir):\n",
    "    level = root.replace(destination_dir, '').count(os.sep)\n",
    "    indent = ' ' * 4 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 4 * (level + 1)\n",
    "    for f in files:\n",
    "        print(f\"{subindent}{f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90af22dc",
   "metadata": {
    "papermill": {
     "duration": 0.079169,
     "end_time": "2024-10-15T20:48:46.344845",
     "exception": false,
     "start_time": "2024-10-15T20:48:46.265676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration for 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2263f31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:48:46.545883Z",
     "iopub.status.busy": "2024-10-15T20:48:46.545074Z",
     "iopub.status.idle": "2024-10-15T20:48:54.055727Z",
     "shell.execute_reply": "2024-10-15T20:48:54.054436Z"
    },
    "papermill": {
     "duration": 7.591288,
     "end_time": "2024-10-15T20:48:54.057967",
     "exception": false,
     "start_time": "2024-10-15T20:48:46.466679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file saved at: /kaggle/working/create_config/Semantic_Segmentation_50Epochs_NewModel.yaml\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 10\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-2/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: ''\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Semantic_Segmentation_50Epochs_NewModel\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_models\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 5\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0002\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dlcv.utils import create_config\n",
    "#this function from utils.py takes the following arguments\n",
    "run_name = 'Semantic_Segmentation_50Epochs_NewModel'\n",
    "\n",
    "# Choose a Backbone for the FasterRCNN Model\n",
    "backbone = 'mobilenet'   # (Options- 'resnet50', 'resnet101', 'mobilenet')\n",
    "\n",
    "# Scheduler and Optimizer Hyper-Parameters.\n",
    "base_lr = 0.0002  # Learning Rate\n",
    "milestones = [10, 20]\n",
    "gamma = 0.1\n",
    "\n",
    "# Training Hyper-Parameters\n",
    "batch_size = 8          #(Resnet50: 4, Resnet101: 2, MobileNet: 8)\n",
    "num_epochs = 50         #(Avg. Time per Epoch: Resnet50- 4:20, Resnet101- 5:45, Mobilenet: 3:43 )\n",
    "early_stopping = False\n",
    "\n",
    "# Augmentation Parameters\n",
    "horizontal_flip_prob = 0.5\n",
    "rotation_degrees = 10\n",
    "crop_size = [256,256]\n",
    "pretrained_weights= ''\n",
    "save_path = '/kaggle/working/saved_models'\n",
    "\n",
    "config_file_path = create_config(run_name, backbone, base_lr,\n",
    "                                 batch_size, num_epochs, horizontal_flip_prob,\n",
    "                                rotation_degrees, crop_size, milestones, gamma, \n",
    "                                early_stopping, pretrained_weights, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b45ed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:48:54.217502Z",
     "iopub.status.busy": "2024-10-15T20:48:54.216704Z",
     "iopub.status.idle": "2024-10-15T20:48:54.221402Z",
     "shell.execute_reply": "2024-10-15T20:48:54.220527Z"
    },
    "papermill": {
     "duration": 0.086015,
     "end_time": "2024-10-15T20:48:54.223867",
     "exception": false,
     "start_time": "2024-10-15T20:48:54.137852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Path to the config file you want to use\n",
    "#config_file = 'config_kaggle.yaml'#yaml file name here\n",
    "#config_file_path = '/kaggle/working/repository_content/config/' + config_file\n",
    "os.environ['CONFIG_FILE'] = config_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a797b34b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T20:48:54.388327Z",
     "iopub.status.busy": "2024-10-15T20:48:54.387932Z",
     "iopub.status.idle": "2024-10-16T07:28:06.775110Z",
     "shell.execute_reply": "2024-10-16T07:28:06.774012Z"
    },
    "papermill": {
     "duration": 38357.925237,
     "end_time": "2024-10-16T07:28:12.232554",
     "exception": false,
     "start_time": "2024-10-15T20:48:54.307317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/material_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
      "  0%|          | 0.00/13.6M [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using configuration file: /kaggle/working/create_config/Semantic_Segmentation_50Epochs_NewModel.yaml\n",
      "Configuration for this run:\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 10\n",
      "CONFIG_FILE_PATH: /kaggle/working/create_config/Semantic_Segmentation_50Epochs_NewModel.yaml\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-2/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: ''\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Semantic_Segmentation_50Epochs_NewModel\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_models\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 5\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0002\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 50\n",
      "\n",
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 111MB/s] \n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Training: 100%|██████████| 2000/2000 [09:07<00:00,  3.65it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:39<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.3273, Test Loss: 0.3132, Test IoU (Material): 0.2491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:06<00:00,  3.66it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:27<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Train Loss: 0.3107, Test Loss: 0.3089, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:55<00:00,  3.74it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Train Loss: 0.3095, Test Loss: 0.3085, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [07:46<00:00,  4.29it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:29<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Train Loss: 0.3095, Test Loss: 0.3081, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [06:03<00:00,  5.50it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:33<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Train Loss: 0.3095, Test Loss: 0.3081, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [05:02<00:00,  6.62it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:35<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Train Loss: 0.3095, Test Loss: 0.3079, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:55<00:00,  6.77it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:30<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Train Loss: 0.3095, Test Loss: 0.3078, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:29<00:00,  7.43it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:30<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Train Loss: 0.3095, Test Loss: 0.3076, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:12<00:00,  7.91it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:28<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Train Loss: 0.3095, Test Loss: 0.3076, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [04:36<00:00,  7.23it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:33<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Train Loss: 0.3095, Test Loss: 0.3072, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [05:40<00:00,  5.87it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:27<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Train Loss: 0.3095, Test Loss: 0.3072, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [06:49<00:00,  4.88it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:28<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Train Loss: 0.3095, Test Loss: 0.3073, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [07:46<00:00,  4.29it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:28<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Train Loss: 0.3095, Test Loss: 0.3072, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:25<00:00,  3.96it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:28<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Train Loss: 0.3095, Test Loss: 0.3073, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:47<00:00,  3.79it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:28<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Train Loss: 0.3095, Test Loss: 0.3072, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:00<00:00,  3.70it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:30<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:11<00:00,  3.27it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:34<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Train Loss: 0.3095, Test Loss: 0.3072, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:09<00:00,  3.28it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:26<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:05<00:00,  3.30it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:59<00:00,  3.34it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Train Loss: 0.3095, Test Loss: 0.3070, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:02<00:00,  3.32it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Train Loss: 0.3095, Test Loss: 0.3070, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:37<00:00,  3.47it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:33<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Train Loss: 0.3095, Test Loss: 0.3072, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:57<00:00,  3.35it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:30<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:04<00:00,  3.31it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:29<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:00<00:00,  3.33it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:38<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Train Loss: 0.3095, Test Loss: 0.3072, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:02<00:00,  3.32it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:06<00:00,  3.30it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:34<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:06<00:00,  3.30it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:36<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:11<00:00,  3.27it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:36<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Train Loss: 0.3095, Test Loss: 0.3070, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:14<00:00,  3.25it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:35<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:16<00:00,  3.24it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:35<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Train Loss: 0.3095, Test Loss: 0.3072, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:16<00:00,  3.25it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:37<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Train Loss: 0.3095, Test Loss: 0.3070, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:12<00:00,  3.27it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:34<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:02<00:00,  3.32it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:38<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Train Loss: 0.3095, Test Loss: 0.3070, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:13<00:00,  3.26it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:36<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Train Loss: 0.3095, Test Loss: 0.3072, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:11<00:00,  3.27it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:34<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Train Loss: 0.3095, Test Loss: 0.3070, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:15<00:00,  3.25it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:34<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:01<00:00,  3.32it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:38<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:09<00:00,  3.28it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:13<00:00,  3.26it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:35<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:11<00:00,  3.27it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:36<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:03<00:00,  3.32it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:34<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Train Loss: 0.3095, Test Loss: 0.3070, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:05<00:00,  3.30it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:10<00:00,  3.28it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:01<00:00,  3.32it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:34<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Train Loss: 0.3095, Test Loss: 0.3070, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:09<00:00,  3.28it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:34<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:16<00:00,  3.25it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:37<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:09<00:00,  3.28it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Train Loss: 0.3095, Test Loss: 0.3070, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:02<00:00,  3.32it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:41<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:16<00:00,  3.25it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:40<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n",
      "Train Loss: 0.3095, Test Loss: 0.3071, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'repository_content/train.py', '--config', '/kaggle/working/create_config/Semantic_Segmentation_50Epochs_NewModel.yaml', '--mode', 'train'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from dlcv.train import main as train_main\n",
    "from dlcv.config import get_cfg_defaults\n",
    "cfg = get_cfg_defaults()\n",
    "print(cfg.DATA.MATERIAL_ROOT)\n",
    "subprocess.run(['python', 'repository_content/train.py', '--config', config_file_path, '--mode', 'train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "062c2910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T07:28:31.803139Z",
     "iopub.status.busy": "2024-10-16T07:28:31.802270Z",
     "iopub.status.idle": "2024-10-16T07:28:31.817178Z",
     "shell.execute_reply": "2024-10-16T07:28:31.816011Z"
    },
    "papermill": {
     "duration": 9.776999,
     "end_time": "2024-10-16T07:28:31.819237",
     "exception": false,
     "start_time": "2024-10-16T07:28:22.042238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file saved at: /kaggle/working/create_config/Visualization_50Epochs.yaml\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 11\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-2/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: /kaggle/input/deeplabv3plus_mobilenet/pytorch/semantic_segmentation_50epoch/2/Semantic_Segmentation_100Epochs.pth\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Visualization_50Epochs\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_prediction\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 5\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0005\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#this function from utils.py takes the following arguments\n",
    "from dlcv.utils import create_config\n",
    "run_name = 'Visualization_50Epochs'\n",
    "\n",
    "# Choose a Backbone for the FasterRCNN Model\n",
    "backbone = 'mobilenet'   # (Options- 'resnet50', 'resnet101', 'mobilenet')\n",
    "\n",
    "# Scheduler and Optimizer Hyper-Parameters.\n",
    "base_lr = 0.0005  # Learning Rate\n",
    "milestones = [10, 20]\n",
    "gamma = 0.1\n",
    "\n",
    "# Training Hyper-Parameters\n",
    "batch_size = 8          #(Resnet50: 4, Resnet101: 2, MobileNet: 8)\n",
    "num_epochs = 1         #(Avg. Time per Epoch: Resnet50- 4:20, Resnet101- 5:45, Mobilenet: 3:43 )\n",
    "early_stopping = False\n",
    "\n",
    "# Augmentation Parameters\n",
    "horizontal_flip_prob = 0.5\n",
    "rotation_degrees = 11\n",
    "crop_size = [256,256]\n",
    "\n",
    "pretrained_weights= '/kaggle/input/deeplabv3plus_mobilenet/pytorch/semantic_segmentation_50epoch/2/Semantic_Segmentation_100Epochs.pth'\n",
    "save_path = '/kaggle/working/saved_prediction'\n",
    "config_file_path = create_config(run_name, backbone, base_lr,\n",
    "                                 batch_size, num_epochs, horizontal_flip_prob,\n",
    "                                rotation_degrees, crop_size, milestones, gamma,\n",
    "                                early_stopping, pretrained_weights, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b37000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T07:28:51.233731Z",
     "iopub.status.busy": "2024-10-16T07:28:51.233076Z",
     "iopub.status.idle": "2024-10-16T07:29:07.047616Z",
     "shell.execute_reply": "2024-10-16T07:29:07.046522Z"
    },
    "papermill": {
     "duration": 25.361489,
     "end_time": "2024-10-16T07:29:07.050018",
     "exception": false,
     "start_time": "2024-10-16T07:28:41.688529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/dlcv/utils.py:440: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using configuration file: /kaggle/working/create_config/Visualization_50Epochs.yaml\n",
      "Configuration for this run:\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 11\n",
      "CONFIG_FILE_PATH: /kaggle/working/create_config/Visualization_50Epochs.yaml\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-2/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: /kaggle/input/deeplabv3plus_mobilenet/pytorch/semantic_segmentation_50epoch/2/Semantic_Segmentation_100Epochs.pth\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Visualization_50Epochs\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_prediction\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 5\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0005\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 1\n",
      "\n",
      "Device: cuda\n",
      "Input image type: <class 'torch.Tensor'>\n",
      "Input image shape: torch.Size([1, 3, 256, 256])\n",
      "Model output type: <class 'torch.Tensor'>\n",
      "Model output shape: torch.Size([1, 5, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'repository_content/train.py', '--config', '/kaggle/working/create_config/Visualization_50Epochs.yaml', '--mode', 'single_image', '--image_path', '/kaggle/working/repository_content/images/bicycle.jpg'], returncode=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run(['python', 'repository_content/train.py', '--config', config_file_path, '--mode', 'single_image', '--image_path', '/kaggle/working/repository_content/images/bicycle.jpg'])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5498199,
     "sourceId": 9109780,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5743755,
     "sourceId": 9449794,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 110102,
     "modelInstanceId": 85872,
     "sourceId": 102419,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 110102,
     "modelInstanceId": 100310,
     "sourceId": 121905,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38596.978112,
   "end_time": "2024-10-16T07:29:18.241095",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-15T20:46:01.262983",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
