{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37fc9742",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-23T14:34:22.294393Z",
     "iopub.status.busy": "2024-09-23T14:34:22.293758Z",
     "iopub.status.idle": "2024-09-23T14:36:54.498009Z",
     "shell.execute_reply": "2024-09-23T14:36:54.496867Z"
    },
    "papermill": {
     "duration": 152.211756,
     "end_time": "2024-09-23T14:36:54.500760",
     "exception": false,
     "start_time": "2024-09-23T14:34:22.289004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git\r\n",
      "  Cloning https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git to /tmp/pip-req-build-4o1b8x21\r\n",
      "  Running command git clone --filter=blob:none --quiet 'https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git' /tmp/pip-req-build-4o1b8x21\r\n",
      "  Resolved https://haaroonafroz:****@github.com/haaroonafroz/DeeplabV3Plus_MaterialSegmentation.git to commit 954ade100ea3f0f70e2b9531e4952989d7375cb8\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (8.1.1)\r\n",
      "Collecting torch==2.3.0 (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\r\n",
      "Collecting torchvision==0.18.0 (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\r\n",
      "Collecting torchaudio==2.3.0 (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.66.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.7.5)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.2.2)\r\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.12.2)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (6.0.1)\r\n",
      "Collecting yacs (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\r\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.26.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2024.2.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.3.0 (from torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.18.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (9.5.0)\r\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.9.0.post0)\r\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.0.0)\r\n",
      "Requirement already satisfied: pluggy<2.0,>=1.4 in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.4.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.2.0)\r\n",
      "Requirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.0.1)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.11.4)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.4.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (3.2.0)\r\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.10/site-packages (from seaborn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.1.4)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2023.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.0->HTCV_DeeplabV3Plus_MaterialSegmentation==0.0.1) (1.3.0)\r\n",
      "Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\r\n",
      "Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: HTCV_DeeplabV3Plus_MaterialSegmentation\r\n",
      "  Building wheel for HTCV_DeeplabV3Plus_MaterialSegmentation (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for HTCV_DeeplabV3Plus_MaterialSegmentation: filename=HTCV_DeeplabV3Plus_MaterialSegmentation-0.0.1-py3-none-any.whl size=946853 sha256=0917ba5248014f0de2ec57958598fb9212bd1d9b1d23634651ba7ecb07919c0d\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nh8hb6oy/wheels/3a/dd/47/f7229c606648c55ebb6dd9026436f12245ae6107f066c04dc8\r\n",
      "Successfully built HTCV_DeeplabV3Plus_MaterialSegmentation\r\n",
      "Installing collected packages: yacs, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio, HTCV_DeeplabV3Plus_MaterialSegmentation\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.1.2\r\n",
      "    Uninstalling torch-2.1.2:\r\n",
      "      Successfully uninstalled torch-2.1.2\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.16.2\r\n",
      "    Uninstalling torchvision-0.16.2:\r\n",
      "      Successfully uninstalled torchvision-0.16.2\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 2.1.2\r\n",
      "    Uninstalling torchaudio-2.1.2:\r\n",
      "      Successfully uninstalled torchaudio-2.1.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "fastai 2.7.14 requires torch<2.3,>=1.10, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed HTCV_DeeplabV3Plus_MaterialSegmentation-0.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 torchaudio-2.3.0 torchvision-0.18.0 triton-2.3.0 yacs-0.1.8\r\n"
     ]
    }
   ],
   "source": [
    "token = \"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\"#token here\n",
    "user = \"haaroonafroz\" #username here\n",
    "repo_name = \"DeeplabV3Plus_MaterialSegmentation\" #repository name here\n",
    "url = f\"https://{user}:{token}@github.com/{user}/{repo_name}.git\"\n",
    "\n",
    "!pip install git+{url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11c5629c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T14:36:54.679107Z",
     "iopub.status.busy": "2024-09-23T14:36:54.677715Z",
     "iopub.status.idle": "2024-09-23T14:36:54.703976Z",
     "shell.execute_reply": "2024-09-23T14:36:54.702364Z"
    },
    "papermill": {
     "duration": 0.118532,
     "end_time": "2024-09-23T14:36:54.706263",
     "exception": false,
     "start_time": "2024-09-23T14:36:54.587731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repository_content/\n",
      "    dataset.py\n",
      "    train.py\n",
      "    visualize.py\n",
      "    training.py\n",
      "    utils.py\n",
      "    config.py\n",
      "    __init__.py\n",
      "    plot.py\n",
      "    model.py\n",
      "    saved_models/\n",
      "        test_model.pth\n",
      "        underfitting_run.pth\n",
      "        fixture_weights_dont_delete_this.pth\n",
      "    __pycache__/\n",
      "        visualize.cpython-310.pyc\n",
      "        dataset.cpython-310.pyc\n",
      "        model.cpython-310.pyc\n",
      "        plot.cpython-310.pyc\n",
      "        config.cpython-310.pyc\n",
      "        training.cpython-310.pyc\n",
      "        train.cpython-310.pyc\n",
      "        utils.cpython-310.pyc\n",
      "        __init__.cpython-310.pyc\n",
      "    images/\n",
      "        person_dog.jpg\n",
      "        bicycle.jpg\n",
      "        .gitkeep\n",
      "        boat.jpg\n",
      "        airplane.jpg\n",
      "    results/\n",
      "        .gitkeep\n",
      "    config/\n",
      "        config1.yaml\n",
      "        config_kaggle.yaml\n",
      "        config3.yaml\n",
      "        config2.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import dlcv  # Assuming the repository is installed and accessible as a Python package\n",
    "\n",
    "# Determine the source directory from the installed package location\n",
    "source_dir = os.path.dirname(dlcv.__file__)\n",
    "destination_dir = os.path.join(os.getcwd(), 'repository_content')\n",
    "\n",
    "# Create the destination directory\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Copy contents from the source directory to the destination directory\n",
    "for item in os.listdir(source_dir):\n",
    "    source_item = os.path.join(source_dir, item)\n",
    "    destination_item = os.path.join(destination_dir, item)\n",
    "    if os.path.isdir(source_item):\n",
    "        shutil.copytree(source_item, destination_item, dirs_exist_ok=True)\n",
    "    else:\n",
    "        shutil.copy2(source_item, destination_item)\n",
    "\n",
    "# List the contents of the destination directory\n",
    "for root, dirs, files in os.walk(destination_dir):\n",
    "    level = root.replace(destination_dir, '').count(os.sep)\n",
    "    indent = ' ' * 4 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 4 * (level + 1)\n",
    "    for f in files:\n",
    "        print(f\"{subindent}{f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30c3fca",
   "metadata": {
    "papermill": {
     "duration": 0.087555,
     "end_time": "2024-09-23T14:36:54.880418",
     "exception": false,
     "start_time": "2024-09-23T14:36:54.792863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration for 50 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ae6fec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T14:36:55.112771Z",
     "iopub.status.busy": "2024-09-23T14:36:55.111827Z",
     "iopub.status.idle": "2024-09-23T14:37:04.282711Z",
     "shell.execute_reply": "2024-09-23T14:37:04.281247Z"
    },
    "papermill": {
     "duration": 9.264261,
     "end_time": "2024-09-23T14:37:04.284930",
     "exception": false,
     "start_time": "2024-09-23T14:36:55.020669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file saved at: /kaggle/working/create_config/Semantic_Segmentation_100Epochs.yaml\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 11\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-2/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: /kaggle/input/deeplabv3plus_mobilenet/pytorch/semantic_segmentation_50epoch/1/Semantic_Segmentation_50Epochs.pth\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Semantic_Segmentation_100Epochs\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_models\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 4\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0005\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dlcv.utils import create_config\n",
    "#this function from utils.py takes the following arguments\n",
    "run_name = 'Semantic_Segmentation_100Epochs'\n",
    "\n",
    "# Choose a Backbone for the FasterRCNN Model\n",
    "backbone = 'mobilenet'   # (Options- 'resnet50', 'resnet101', 'mobilenet')\n",
    "\n",
    "# Scheduler and Optimizer Hyper-Parameters.\n",
    "base_lr = 0.0005  # Learning Rate\n",
    "milestones = [10, 20]\n",
    "gamma = 0.1\n",
    "\n",
    "# Training Hyper-Parameters\n",
    "batch_size = 8          #(Resnet50: 4, Resnet101: 2, MobileNet: 8)\n",
    "num_epochs = 50         #(Avg. Time per Epoch: Resnet50- 4:20, Resnet101- 5:45, Mobilenet: 3:43 )\n",
    "early_stopping = False\n",
    "\n",
    "# Augmentation Parameters\n",
    "horizontal_flip_prob = 0.5\n",
    "rotation_degrees = 11\n",
    "crop_size = [256,256]\n",
    "pretrained_weights= '/kaggle/input/deeplabv3plus_mobilenet/pytorch/semantic_segmentation_50epoch/1/Semantic_Segmentation_50Epochs.pth'\n",
    "save_path = '/kaggle/working/saved_models'\n",
    "\n",
    "#pretrained_weights= '/kaggle/input/fasterrcnn_resnet101_pretrained_40epochs/pytorch/frcnn_resnet101_pretrained/1/resnet101_config.pth'\n",
    "\n",
    "\n",
    "config_file_path = create_config(run_name, backbone, base_lr,\n",
    "                                 batch_size, num_epochs, horizontal_flip_prob,\n",
    "                                rotation_degrees, crop_size, milestones, gamma, \n",
    "                                early_stopping, pretrained_weights, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebe0a93d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T14:37:04.433986Z",
     "iopub.status.busy": "2024-09-23T14:37:04.433557Z",
     "iopub.status.idle": "2024-09-23T14:37:04.437863Z",
     "shell.execute_reply": "2024-09-23T14:37:04.437016Z"
    },
    "papermill": {
     "duration": 0.080275,
     "end_time": "2024-09-23T14:37:04.439683",
     "exception": false,
     "start_time": "2024-09-23T14:37:04.359408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Path to the config file you want to use\n",
    "#config_file = 'config_kaggle.yaml'#yaml file name here\n",
    "#config_file_path = '/kaggle/working/repository_content/config/' + config_file\n",
    "os.environ['CONFIG_FILE'] = config_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "481870ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T14:37:04.586584Z",
     "iopub.status.busy": "2024-09-23T14:37:04.586241Z",
     "iopub.status.idle": "2024-09-24T02:05:10.022359Z",
     "shell.execute_reply": "2024-09-24T02:05:10.021265Z"
    },
    "papermill": {
     "duration": 41290.863385,
     "end_time": "2024-09-24T02:05:15.375859",
     "exception": false,
     "start_time": "2024-09-23T14:37:04.512474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/material_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
      "  0%|          | 0.00/13.6M [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using configuration file: /kaggle/working/create_config/Semantic_Segmentation_100Epochs.yaml\n",
      "Configuration for this run:\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 11\n",
      "CONFIG_FILE_PATH: /kaggle/working/create_config/Semantic_Segmentation_100Epochs.yaml\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-2/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: /kaggle/input/deeplabv3plus_mobilenet/pytorch/semantic_segmentation_50epoch/1/Semantic_Segmentation_50Epochs.pth\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Semantic_Segmentation_100Epochs\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_models\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 4\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0005\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 50\n",
      "\n",
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 133MB/s]\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Training: 100%|██████████| 2000/2000 [09:46<00:00,  3.41it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:46<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.1245, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:39<00:00,  3.45it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:30<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:33<00:00,  3.49it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:33<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:27<00:00,  3.52it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:18<00:00,  3.58it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:33<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:08<00:00,  3.65it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:30<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:59<00:00,  3.71it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:30<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:42<00:00,  3.83it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:26<00:00,  3.95it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:30<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:13<00:00,  4.05it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:22<00:00,  3.98it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:47<00:00,  3.79it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:33<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [08:57<00:00,  3.72it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:00<00:00,  3.70it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:04<00:00,  3.67it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [09:12<00:00,  3.62it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:28<00:00,  3.18it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:36<00:00,  3.14it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:43<00:00,  3.11it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:46<00:00,  3.09it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:46<00:00,  3.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:46<00:00,  3.09it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:30<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:46<00:00,  3.09it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:47<00:00,  3.09it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:46<00:00,  3.09it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:46<00:00,  3.09it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:47<00:00,  3.09it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:46<00:00,  3.09it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:33<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:39<00:00,  3.13it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:33<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:47<00:00,  3.09it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:46<00:00,  3.09it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:46<00:00,  3.09it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:46<00:00,  3.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:30<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:45<00:00,  3.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:46<00:00,  3.09it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:45<00:00,  3.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:45<00:00,  3.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:45<00:00,  3.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:30<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:40<00:00,  3.12it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:30<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:42<00:00,  3.11it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:46<00:00,  3.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:46<00:00,  3.09it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:45<00:00,  3.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:30<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:44<00:00,  3.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:45<00:00,  3.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:30<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:45<00:00,  3.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:44<00:00,  3.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:45<00:00,  3.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:33<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:45<00:00,  3.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:32<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2000/2000 [10:44<00:00,  3.10it/s]\n",
      "Evaluation: 100%|██████████| 500/500 [02:31<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n",
      "Train Loss: 0.0000, Test Loss: 0.0000, Test IoU (Material): 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'repository_content/train.py', '--config', '/kaggle/working/create_config/Semantic_Segmentation_100Epochs.yaml', '--mode', 'train'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from dlcv.train import main as train_main\n",
    "from dlcv.config import get_cfg_defaults\n",
    "cfg = get_cfg_defaults()\n",
    "print(cfg.DATA.MATERIAL_ROOT)\n",
    "subprocess.run(['python', 'repository_content/train.py', '--config', config_file_path, '--mode', 'train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b2e41bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T02:05:34.305177Z",
     "iopub.status.busy": "2024-09-24T02:05:34.304834Z",
     "iopub.status.idle": "2024-09-24T02:05:34.317447Z",
     "shell.execute_reply": "2024-09-24T02:05:34.316334Z"
    },
    "papermill": {
     "duration": 9.599288,
     "end_time": "2024-09-24T02:05:34.319551",
     "exception": false,
     "start_time": "2024-09-24T02:05:24.720263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file saved at: /kaggle/working/create_config/Visualization_100Epochs.yaml\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 11\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-2/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: /kaggle/working/saved_models/Semantic_Segmentation_100Epochs.pth\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Visualization_100Epochs\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_prediction\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 4\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0005\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#this function from utils.py takes the following arguments\n",
    "from dlcv.utils import create_config\n",
    "run_name = 'Visualization_100Epochs'\n",
    "\n",
    "# Choose a Backbone for the FasterRCNN Model\n",
    "backbone = 'mobilenet'   # (Options- 'resnet50', 'resnet101', 'mobilenet')\n",
    "\n",
    "# Scheduler and Optimizer Hyper-Parameters.\n",
    "base_lr = 0.0005  # Learning Rate\n",
    "milestones = [10, 20]\n",
    "gamma = 0.1\n",
    "\n",
    "# Training Hyper-Parameters\n",
    "batch_size = 8          #(Resnet50: 4, Resnet101: 2, MobileNet: 8)\n",
    "num_epochs = 1         #(Avg. Time per Epoch: Resnet50- 4:20, Resnet101- 5:45, Mobilenet: 3:43 )\n",
    "early_stopping = False\n",
    "\n",
    "# Augmentation Parameters\n",
    "horizontal_flip_prob = 0.5\n",
    "rotation_degrees = 11\n",
    "crop_size = [256,256]\n",
    "\n",
    "pretrained_weights= '/kaggle/working/saved_models/Semantic_Segmentation_100Epochs.pth'\n",
    "save_path = '/kaggle/working/saved_prediction'\n",
    "config_file_path = create_config(run_name, backbone, base_lr,\n",
    "                                 batch_size, num_epochs, horizontal_flip_prob,\n",
    "                                rotation_degrees, crop_size, milestones, gamma,\n",
    "                                early_stopping, pretrained_weights, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34e2e61f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T02:05:52.958161Z",
     "iopub.status.busy": "2024-09-24T02:05:52.957430Z",
     "iopub.status.idle": "2024-09-24T02:06:06.266312Z",
     "shell.execute_reply": "2024-09-24T02:06:06.265327Z"
    },
    "papermill": {
     "duration": 22.596657,
     "end_time": "2024-09-24T02:06:06.268366",
     "exception": false,
     "start_time": "2024-09-24T02:05:43.671709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using configuration file: /kaggle/working/create_config/Visualization_100Epochs.yaml\n",
      "Configuration for this run:\n",
      "AUGMENTATION:\n",
      "  CROP_SIZE:\n",
      "  - 256\n",
      "  - 256\n",
      "  HORIZONTAL_FLIP_PROB: 0.5\n",
      "  ROTATION_DEGREES: 11\n",
      "CONFIG_FILE_PATH: /kaggle/working/create_config/Visualization_100Epochs.yaml\n",
      "DATA:\n",
      "  DATASET: MaterialDataset\n",
      "  MATERIAL_ROOT: /kaggle/input/material-dataset-2/Material_dataset\n",
      "MISC:\n",
      "  FROZEN_LAYERS: []\n",
      "  NO_CUDA: false\n",
      "  PRETRAINED_WEIGHTS: /kaggle/working/saved_models/Semantic_Segmentation_100Epochs.pth\n",
      "  RESULTS_CSV: ./results\n",
      "  RUN_NAME: Visualization_100Epochs\n",
      "  SAVE_MODEL_PATH: ./saved_models\n",
      "  SAVE_PREDICTION: /kaggle/working/saved_prediction\n",
      "MODEL:\n",
      "  BACKBONE: mobilenet\n",
      "  NUM_CLASSES_MATERIAL: 4\n",
      "TRAIN:\n",
      "  BASE_LR: 0.0005\n",
      "  BATCH_SIZE: 8\n",
      "  EARLY_STOPPING: false\n",
      "  GAMMA: 0.1\n",
      "  MILESTONES:\n",
      "  - 10\n",
      "  - 20\n",
      "  NUM_EPOCHS: 1\n",
      "\n",
      "Device: cuda\n",
      "Input image type: <class 'torch.Tensor'>\n",
      "Input image shape: torch.Size([1, 3, 256, 256])\n",
      "Model output type: <class 'torch.Tensor'>\n",
      "Model output shape: torch.Size([1, 4, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'repository_content/train.py', '--config', '/kaggle/working/create_config/Visualization_100Epochs.yaml', '--mode', 'single_image', '--image_path', '/kaggle/working/repository_content/images/airplane.jpg'], returncode=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run(['python', 'repository_content/train.py', '--config', config_file_path, '--mode', 'single_image', '--image_path', '/kaggle/working/repository_content/images/airplane.jpg'])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5498199,
     "sourceId": 9109780,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5743755,
     "sourceId": 9449794,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 110102,
     "modelInstanceId": 85872,
     "sourceId": 102419,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 110102,
     "modelInstanceId": 100310,
     "sourceId": 119285,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 41517.676327,
   "end_time": "2024-09-24T02:06:17.174016",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-23T14:34:19.497689",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
